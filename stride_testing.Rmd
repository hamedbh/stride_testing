---
title: "Testing R on Stride"
output: html_notebook
---
Notebook for testing R on STRIDE. Runs through downloading data, plotting various elements and then running machine learning algorithms to predict outcome.

Dataset used is the [UCI Adult][1] data, which allows for binary prediction of whether or not given adult has an income above $50,000.

```{r load libraries, message=FALSE, warning=FALSE, paged.print=FALSE}
library(purrr)
# library(data.table)
library(dplyr)
library(ggplot2)
# library(ggthemes)
library(tidyr)
library(readr)
library(caret)
library(xgboost)
library(Matrix)
library(stringi)
```

```{r get data}
data_url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
data_filepath <- "./data/adult.csv"
if (!file.exists(data_filepath)) {
    download.file(data_url, data_filepath)
}
headers <- c("age", "workclass", "fnlwgt", "education", "education_num", 
             "marital_status", "occupation", "relationship", "race", 
             "sex", "cap_gain", "cap_loss", "hrs_per_week", "native_country", 
             "income_level")
df <- read_csv(data_filepath, col_names = headers)
```

Now do some quick plotting to check for obvious problems with the dataset (e.g. imbalanced classes).

```{r plotting variables}
df %>% 
    dplyr::select_if(is.character) %>% 
    gather() %>% 
    ggplot(aes(x = value)) +
    geom_bar() +
    facet_wrap(~ key, scales = "free_x") + 
    theme_minimal() +
    # theme_tufte() +
    theme(axis.text.x = element_blank())

df %>% 
    dplyr::select_if(is.integer) %>% 
    gather() %>% 
    ggplot(aes(x = value)) +
    geom_histogram(bins = 20) +
    facet_wrap(~ key, scales = "free_x") + 
    theme_minimal() +
    # theme_tufte() +
    theme(axis.text.x = element_blank())
```

Check for, and handle, missing data.

```{r missing data}
na_counts <- sapply(df, function(y) {
    sum(length(which(is.na(y))))
})
na_counts
```

```{r}
full_matrix <- df %>% 
    mutate(income_level = if_else(
        income_level == ">50K", 
        1L, 
        0L)) %>% 
    mutate_if(is.character, as.factor) %>% 
    data.matrix()

# sparse_matrix <- sparse.model.matrix(
#     income_level ~ ., 
#     data = df %>% 
#         mutate(income_level = if_else(
#             income_level == ">50K", 
#             1L, 
#             0L)))
#     
# head(sparse_matrix)
output_vector <- as.integer(df[, "income_level"] == ">50K")
# head(output_vector)
train_indxs <- createDataPartition(df$income_level, 
                                   times = 1, 
                                   p = 0.8, 
                                   list = FALSE)

train <- full_matrix[train_indxs, seq_len(ncol(full_matrix) - 1)]
test  <- full_matrix[-train_indxs, seq_len(ncol(full_matrix) - 1)] 
train_labels <- output_vector[train_indxs]
test_labels <- output_vector[-train_indxs]
```


```{r}
dtrain <- xgb.DMatrix(data = train, label = train_labels) #, missing = 0L)
dtest <- xgb.DMatrix(data = test, label = test_labels)
my_cv <- xgb.cv(params = list(eta = 0.01, 
                              max_depth = 4, 
                              objective = "binary:logistic"), 
                data = dtrain, 
                nrounds = 2000L, 
                nfold = 5, 
                prediction = TRUE, 
                showsd = TRUE, 
                metrics = "logloss", 
                stratified = TRUE, 
                print_every_n = 100L)
```

```{r}
my_cv[["evaluation_log"]] %>% 
    gather(key = "partition", value = "error", 
           train_logloss_mean, test_logloss_mean) %>% 
    dplyr::select(iter, partition, error) %>% 
    mutate(partition = stri_extract_first_regex(partition, "^[a-z]+")) %>% 
    ggplot(aes(x = iter, y = error, colour = partition)) +
    geom_point() +
    viridis::scale_colour_viridis(discrete = TRUE, option = "D") + 
    theme_minimal()
```

```{r}
best_iter <- which.min(my_cv$evaluation_log$test_logloss_mean)
my_xgb <- xgb.train(params = list(eta = 0.1, 
                              max_depth = 4, 
                              objective = "binary:logistic"), 
                    data = dtrain, 
                    nrounds = best_iter, 
                    metrics = "logloss")
```

```{r}
thresholds <- seq(0.1, 0.9, by = 0.05)
F1_scores <- map_dbl(thresholds, 
                     function(x) {
                         tmp_preds <- as.integer(predict(my_xgb, dtest) > x)
                         conmat <- confusionMatrix(as.factor(tmp_preds), 
                                                   as.factor(test_labels))
                         conmat[["byClass"]][["F1"]]
})
best_threshold <- thresholds[which.max(F1_scores)]
paste("Best threshold tested is", best_threshold)
preds <- as.integer(predict(my_xgb, dtest) > best_threshold)
conf_mat <- confusionMatrix(as.factor(preds), as.factor(test_labels))
conf_mat
```



[1]: https://archive.ics.uci.edu/ml/datasets/adult